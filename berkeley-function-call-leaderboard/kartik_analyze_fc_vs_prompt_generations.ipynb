{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading score/gpt-3.5-turbo-0125-FC/executable_multiple_function_score_pallavi_annotated.json: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "# first load prompt results\n",
    "# {\"idx\": 3, \"result\": \"[calculate_displacement(initial_velocity=15, acceleration=9.8, time=10)]\", \"input_token_count\": 473, \"output_token_count\": 19, \"latency\": 0.47064781188964844}\n",
    "\n",
    "error_results_df_list = []\n",
    "full_results_df_list = []\n",
    "acc_dict = {'model': [], 'filename': [], 'accuracy': [], 'correct_count': [], 'total_count': []}\n",
    "for model in ['gpt-3.5-turbo-0125', 'gpt-3.5-turbo-0125-FC']:\n",
    "    # model = 'gpt-3.5-turbo-0125'\n",
    "    results_dir = f'score/{model}'\n",
    "    json_files = [f'{results_dir}/{f}' for f in os.listdir(results_dir) if f.endswith('.json')]\n",
    "    for filename in json_files:\n",
    "        with open(filename, 'r') as f:\n",
    "            try:\n",
    "                data = [json.loads(line) for line in f.readlines()]\n",
    "                # skip the accuracy line\n",
    "                df = pd.DataFrame(data[1:])\n",
    "                df['filename'] = filename.split('/')[-1]\n",
    "                error_results_df_list.append(df)\n",
    "                # parse out accuracy_info\n",
    "                acc_info = data[0]\n",
    "                acc_dict['filename'].append(filename.split('/')[-1])\n",
    "                acc_info['model'] = model\n",
    "                for key in acc_info.keys():\n",
    "                    acc_dict[key].append(acc_info[key])\n",
    "            except Exception as e:\n",
    "                print(f'Error reading {filename}: {e}')\n",
    "\n",
    "# now read full results\n",
    "for model in ['gpt-3.5-turbo-0125', 'gpt-3.5-turbo-0125-FC']:\n",
    "    results_dir = f'result/{model}'\n",
    "    json_files = [f'{results_dir}/{f}' for f in os.listdir(results_dir) if f.endswith('.json')]\n",
    "    for filename in json_files:\n",
    "        with open(filename, 'r') as f:\n",
    "            try:\n",
    "                data = [json.loads(line) for line in f.readlines()]\n",
    "                df = pd.DataFrame(data)\n",
    "                df['filename'] = filename.split('/')[-1]\n",
    "                df['model_name'] = model\n",
    "                full_results_df_list.append(df)\n",
    "            except Exception as e:\n",
    "                print(f'Error reading {filename}: {e}')\n",
    "\n",
    "acc_df = pd.DataFrame(acc_dict)\n",
    "acc_df['metric'] = acc_df['filename'].apply(lambda x: x.split('/')[-1].split('.')[0])\n",
    "error_result_df = pd.concat(error_results_df_list)\n",
    "full_result_df = pd.concat(full_results_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>filename</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>executable_multiple_function_score.json</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>executable_multiple_function_score.json</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>executable_parallel_function_score.json</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>executable_parallel_function_score.json</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>executable_parallel_multiple_function_score.json</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>executable_parallel_multiple_function_score.json</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>executable_simple_score.json</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>executable_simple_score.json</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>java_score.json</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>java_score.json</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>javascript_score.json</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>javascript_score.json</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>multiple_function_score.json</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>multiple_function_score.json</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>parallel_function_score.json</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>parallel_function_score.json</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>parallel_multiple_function_score.json</td>\n",
       "      <td>0.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>parallel_multiple_function_score.json</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>rest_score.json</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>rest_score.json</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>0.552500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                          filename  \\\n",
       "4      gpt-3.5-turbo-0125           executable_multiple_function_score.json   \n",
       "16  gpt-3.5-turbo-0125-FC           executable_multiple_function_score.json   \n",
       "10     gpt-3.5-turbo-0125           executable_parallel_function_score.json   \n",
       "23  gpt-3.5-turbo-0125-FC           executable_parallel_function_score.json   \n",
       "9      gpt-3.5-turbo-0125  executable_parallel_multiple_function_score.json   \n",
       "12  gpt-3.5-turbo-0125-FC  executable_parallel_multiple_function_score.json   \n",
       "2      gpt-3.5-turbo-0125                      executable_simple_score.json   \n",
       "22  gpt-3.5-turbo-0125-FC                      executable_simple_score.json   \n",
       "6      gpt-3.5-turbo-0125                                   java_score.json   \n",
       "13  gpt-3.5-turbo-0125-FC                                   java_score.json   \n",
       "5      gpt-3.5-turbo-0125                             javascript_score.json   \n",
       "18  gpt-3.5-turbo-0125-FC                             javascript_score.json   \n",
       "1      gpt-3.5-turbo-0125                      multiple_function_score.json   \n",
       "17  gpt-3.5-turbo-0125-FC                      multiple_function_score.json   \n",
       "8      gpt-3.5-turbo-0125                      parallel_function_score.json   \n",
       "14  gpt-3.5-turbo-0125-FC                      parallel_function_score.json   \n",
       "7      gpt-3.5-turbo-0125             parallel_multiple_function_score.json   \n",
       "19  gpt-3.5-turbo-0125-FC             parallel_multiple_function_score.json   \n",
       "11     gpt-3.5-turbo-0125                              relevance_score.json   \n",
       "15  gpt-3.5-turbo-0125-FC                              relevance_score.json   \n",
       "3      gpt-3.5-turbo-0125                                   rest_score.json   \n",
       "21  gpt-3.5-turbo-0125-FC                                   rest_score.json   \n",
       "0      gpt-3.5-turbo-0125                                 simple_score.json   \n",
       "20  gpt-3.5-turbo-0125-FC                                 simple_score.json   \n",
       "\n",
       "    accuracy  \n",
       "4   0.720000  \n",
       "16  0.680000  \n",
       "10  0.620000  \n",
       "23  0.720000  \n",
       "9   0.450000  \n",
       "12  0.400000  \n",
       "2   0.780000  \n",
       "22  0.750000  \n",
       "6   0.510000  \n",
       "13  0.530000  \n",
       "5   0.640000  \n",
       "18  0.600000  \n",
       "1   0.720000  \n",
       "17  0.660000  \n",
       "8   0.740000  \n",
       "14  0.860000  \n",
       "7   0.435000  \n",
       "19  0.600000  \n",
       "11  0.600000  \n",
       "15  0.025000  \n",
       "3   0.757143  \n",
       "21  0.757143  \n",
       "0   0.770000  \n",
       "20  0.552500  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df[['model', 'filename', 'accuracy']].sort_values(by=['filename', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-3.5-turbo-0125 : Acc = 66.47058823529412%\n",
      "Model: gpt-3.5-turbo-0125-FC : Acc = 55.76470588235294%\n"
     ]
    }
   ],
   "source": [
    "for model in acc_df['model'].unique():\n",
    "    acc = acc_df[acc_df['model'] == model].correct_count.sum() / acc_df[acc_df['model'] == model].total_count.sum()\n",
    "    print(f'Model: {model} : Acc = {100.0*acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of the accuracies are comparable, the biggest difference makers are:\n",
    "# 1. relevance_score.json: 60% (prompt) vs 0 (FC)\n",
    "# 2. simple_score.json: 77% (prompt) vs 55% (FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_category</th>\n",
       "      <th>valid</th>\n",
       "      <th>error</th>\n",
       "      <th>error_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_result_raw</th>\n",
       "      <th>possible_answer</th>\n",
       "      <th>model_result_decoded</th>\n",
       "      <th>filename</th>\n",
       "      <th>model_result</th>\n",
       "      <th>decoded_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Invalid syntax. Failed to decode AST. ]</td>\n",
       "      <td>ast_decoder:decoder_failed</td>\n",
       "      <td>{'question': 'What are the roots of the quadra...</td>\n",
       "      <td>[{'solve_quadratic': {'a': 2, 'b': 5, 'c': 3}}]</td>\n",
       "      <td>{'solve_quadratic': {'a': [2], 'b': [5], 'c': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Nested type checking failed for parameter 'in...</td>\n",
       "      <td>type_error:nested</td>\n",
       "      <td>{'question': 'Calculate the area under the cur...</td>\n",
       "      <td>[calculate_area_under_curve(function='x**2', i...</td>\n",
       "      <td>{'calculate_area_under_curve': {'function': ['...</td>\n",
       "      <td>[{'calculate_area_under_curve': {'function': '...</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Invalid value for parameter 'function': '3*x*...</td>\n",
       "      <td>value_error:string</td>\n",
       "      <td>{'question': 'Calculate the derivative of the ...</td>\n",
       "      <td>[calculate_derivative(function='3*x**2 + 2*x -...</td>\n",
       "      <td>{'calculate_derivative': {'function': ['3x^2 +...</td>\n",
       "      <td>[{'calculate_derivative': {'function': '3*x**2...</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Invalid syntax. Failed to decode AST. ]</td>\n",
       "      <td>ast_decoder:decoder_failed</td>\n",
       "      <td>{'question': 'Calculate the area under the cur...</td>\n",
       "      <td>[{'name': 'integrate', 'parameters': {'functio...</td>\n",
       "      <td>{'integrate': {'function': ['x^3', 'x**3'], 's...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Invalid value for parameter 'function': '2*x*...</td>\n",
       "      <td>value_error:string</td>\n",
       "      <td>{'question': 'Calculate the derivative of the ...</td>\n",
       "      <td>[calculus.derivative(function='2*x**2', value=...</td>\n",
       "      <td>{'calculus.derivative': {'function': ['2*x^2',...</td>\n",
       "      <td>[{'calculus.derivative': {'function': '2*x**2'...</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          model_name test_category  valid  \\\n",
       "0   7  gpt-3.5-turbo-0125        simple  False   \n",
       "1  14  gpt-3.5-turbo-0125        simple  False   \n",
       "2  15  gpt-3.5-turbo-0125        simple  False   \n",
       "3  16  gpt-3.5-turbo-0125        simple  False   \n",
       "4  17  gpt-3.5-turbo-0125        simple  False   \n",
       "\n",
       "                                               error  \\\n",
       "0           [Invalid syntax. Failed to decode AST. ]   \n",
       "1  [Nested type checking failed for parameter 'in...   \n",
       "2  [Invalid value for parameter 'function': '3*x*...   \n",
       "3           [Invalid syntax. Failed to decode AST. ]   \n",
       "4  [Invalid value for parameter 'function': '2*x*...   \n",
       "\n",
       "                   error_type  \\\n",
       "0  ast_decoder:decoder_failed   \n",
       "1           type_error:nested   \n",
       "2          value_error:string   \n",
       "3  ast_decoder:decoder_failed   \n",
       "4          value_error:string   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  {'question': 'What are the roots of the quadra...   \n",
       "1  {'question': 'Calculate the area under the cur...   \n",
       "2  {'question': 'Calculate the derivative of the ...   \n",
       "3  {'question': 'Calculate the area under the cur...   \n",
       "4  {'question': 'Calculate the derivative of the ...   \n",
       "\n",
       "                                    model_result_raw  \\\n",
       "0    [{'solve_quadratic': {'a': 2, 'b': 5, 'c': 3}}]   \n",
       "1  [calculate_area_under_curve(function='x**2', i...   \n",
       "2  [calculate_derivative(function='3*x**2 + 2*x -...   \n",
       "3  [{'name': 'integrate', 'parameters': {'functio...   \n",
       "4  [calculus.derivative(function='2*x**2', value=...   \n",
       "\n",
       "                                     possible_answer  \\\n",
       "0  {'solve_quadratic': {'a': [2], 'b': [5], 'c': ...   \n",
       "1  {'calculate_area_under_curve': {'function': ['...   \n",
       "2  {'calculate_derivative': {'function': ['3x^2 +...   \n",
       "3  {'integrate': {'function': ['x^3', 'x**3'], 's...   \n",
       "4  {'calculus.derivative': {'function': ['2*x^2',...   \n",
       "\n",
       "                                model_result_decoded           filename  \\\n",
       "0                                                NaN  simple_score.json   \n",
       "1  [{'calculate_area_under_curve': {'function': '...  simple_score.json   \n",
       "2  [{'calculate_derivative': {'function': '3*x**2...  simple_score.json   \n",
       "3                                                NaN  simple_score.json   \n",
       "4  [{'calculus.derivative': {'function': '2*x**2'...  simple_score.json   \n",
       "\n",
       "  model_result decoded_result  \n",
       "0          NaN            NaN  \n",
       "1          NaN            NaN  \n",
       "2          NaN            NaN  \n",
       "3          NaN            NaN  \n",
       "4          NaN            NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3_5_fc_relevance_errors = error_result_df[(error_result_df['filename'] == 'relevance_score.json') & (error_result_df['model_name'] == 'gpt-3.5-turbo-0125-FC')]\n",
    "gpt3_5_fc_relevance_results = full_result_df[(full_result_df['filename'] == 'gorilla_openfunctions_v1_test_relevance_result.json') & (full_result_df['model_name'] == 'gpt-3.5-turbo-0125-FC')]\n",
    "gpt3_5_prompt_relevance_errors = error_result_df[(error_result_df['filename'] == 'relevance_score.json') & (error_result_df['model_name'] == 'gpt-3.5-turbo-0125')]\n",
    "gpt3_5_prompt_relevance_results = full_result_df[(full_result_df['filename'] == 'gorilla_openfunctions_v1_test_relevance_result.json') & (full_result_df['model_name'] == 'gpt-3.5-turbo-0125')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_relevance_errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_prompt_relevance_errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_relevance_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# takeaway - gpt3.5 FC gets relevance results ALMOST ALWAYS WRONG! 234/240 are wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_category</th>\n",
       "      <th>valid</th>\n",
       "      <th>error</th>\n",
       "      <th>error_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_result_raw</th>\n",
       "      <th>possible_answer</th>\n",
       "      <th>model_result_decoded</th>\n",
       "      <th>filename</th>\n",
       "      <th>model_result</th>\n",
       "      <th>decoded_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'determine_body_mass_index': '{\"weight\": 10,...</td>\n",
       "      <td>[{'determine_body_mass_index': {'weight': 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'math_sum': '{\"numbers\": [1, 2, 3]}'}, {'mat...</td>\n",
       "      <td>[{'math_sum': {'numbers': [1, 2, 3]}}, {'math_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'solve_quadratic_equation': '{\"a\": 3, \"b\": -...</td>\n",
       "      <td>[{'solve_quadratic_equation': {'a': 3, 'b': -2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'find_critical_points': '{\"function\":\"3x + 2...</td>\n",
       "      <td>[{'find_critical_points': {'function': '3x + 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'find_roots': '{\"a\": 0, \"b\": 1, \"c\": 0}'}, {...</td>\n",
       "      <td>[{'find_roots': {'a': 0, 'b': 1, 'c': 0}}, {'f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             model_name test_category  valid  \\\n",
       "0   1  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "1   2  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "2   3  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "3   4  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "4   5  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "\n",
       "                                               error  \\\n",
       "0  [Valid syntax. Successfully decode AST when it...   \n",
       "1  [Valid syntax. Successfully decode AST when it...   \n",
       "2  [Valid syntax. Successfully decode AST when it...   \n",
       "3  [Valid syntax. Successfully decode AST when it...   \n",
       "4  [Valid syntax. Successfully decode AST when it...   \n",
       "\n",
       "                        error_type prompt model_result_raw possible_answer  \\\n",
       "0  relevance_error:decoder_success    NaN              NaN             NaN   \n",
       "1  relevance_error:decoder_success    NaN              NaN             NaN   \n",
       "2  relevance_error:decoder_success    NaN              NaN             NaN   \n",
       "3  relevance_error:decoder_success    NaN              NaN             NaN   \n",
       "4  relevance_error:decoder_success    NaN              NaN             NaN   \n",
       "\n",
       "  model_result_decoded              filename  \\\n",
       "0                  NaN  relevance_score.json   \n",
       "1                  NaN  relevance_score.json   \n",
       "2                  NaN  relevance_score.json   \n",
       "3                  NaN  relevance_score.json   \n",
       "4                  NaN  relevance_score.json   \n",
       "\n",
       "                                        model_result  \\\n",
       "0  [{'determine_body_mass_index': '{\"weight\": 10,...   \n",
       "1  [{'math_sum': '{\"numbers\": [1, 2, 3]}'}, {'mat...   \n",
       "2  [{'solve_quadratic_equation': '{\"a\": 3, \"b\": -...   \n",
       "3  [{'find_critical_points': '{\"function\":\"3x + 2...   \n",
       "4  [{'find_roots': '{\"a\": 0, \"b\": 1, \"c\": 0}'}, {...   \n",
       "\n",
       "                                      decoded_result  \n",
       "0  [{'determine_body_mass_index': {'weight': 10, ...  \n",
       "1  [{'math_sum': {'numbers': [1, 2, 3]}}, {'math_...  \n",
       "2  [{'solve_quadratic_equation': {'a': 3, 'b': -2...  \n",
       "3  [{'find_critical_points': {'function': '3x + 2...  \n",
       "4  [{'find_roots': {'a': 0, 'b': 1, 'c': 0}}, {'f...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_relevance_errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>result</th>\n",
       "      <th>input_token_count</th>\n",
       "      <th>output_token_count</th>\n",
       "      <th>latency</th>\n",
       "      <th>filename</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'determine_body_mass_index': '{\"weight\": 10,...</td>\n",
       "      <td>101</td>\n",
       "      <td>36</td>\n",
       "      <td>0.799414</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'math_sum': '{\"numbers\": [1, 2, 3]}'}, {'mat...</td>\n",
       "      <td>112</td>\n",
       "      <td>52</td>\n",
       "      <td>1.101193</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'solve_quadratic_equation': '{\"a\": 3, \"b\": -...</td>\n",
       "      <td>113</td>\n",
       "      <td>65</td>\n",
       "      <td>1.267069</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'find_critical_points': '{\"function\":\"3x + 2...</td>\n",
       "      <td>133</td>\n",
       "      <td>23</td>\n",
       "      <td>0.650546</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[{'find_roots': '{\"a\": 0, \"b\": 1, \"c\": 0}'}, {...</td>\n",
       "      <td>109</td>\n",
       "      <td>61</td>\n",
       "      <td>1.080612</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                             result  input_token_count  \\\n",
       "0    0  [{'determine_body_mass_index': '{\"weight\": 10,...                101   \n",
       "1    1  [{'math_sum': '{\"numbers\": [1, 2, 3]}'}, {'mat...                112   \n",
       "2    2  [{'solve_quadratic_equation': '{\"a\": 3, \"b\": -...                113   \n",
       "3    3  [{'find_critical_points': '{\"function\":\"3x + 2...                133   \n",
       "4    4  [{'find_roots': '{\"a\": 0, \"b\": 1, \"c\": 0}'}, {...                109   \n",
       "\n",
       "   output_token_count   latency  \\\n",
       "0                  36  0.799414   \n",
       "1                  52  1.101193   \n",
       "2                  65  1.267069   \n",
       "3                  23  0.650546   \n",
       "4                  61  1.080612   \n",
       "\n",
       "                                            filename             model_name  \n",
       "0  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  \n",
       "1  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  \n",
       "2  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  \n",
       "3  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  \n",
       "4  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_relevance_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JESUS CHRIST BFCL! There's a bug in your code.\n",
    "# the ID in the error results is not the same as the idx in the results\n",
    "# the score.json idx is off by 1 from the idx in the results\n",
    "\n",
    "\n",
    "# let's see if we can compare FC vs non-FC for these errors\n",
    "def compare_fc_vs_prompt(fc_errors_df, fc_df, prompt_errors_df, prompt_df, idx=None):\n",
    "    if idx is None:\n",
    "        fc_only_errors = set(fc_errors_df.id.values) - set(prompt_errors_df.id.values)\n",
    "        idx = np.random.choice(list(fc_only_errors))\n",
    "    print(f'Looking at idx: {idx} (WHICH IS SECRETLY) {idx - 1} in the results.json')\n",
    "    print(f\"Error: {fc_errors_df.model_name.unique()[0]}\", fc_errors_df[fc_errors_df['id'] == idx]['error'].item())\n",
    "    print(\"FC Model: \", fc_df[fc_df['idx'] == (idx-1)]['result'].item())\n",
    "\n",
    "    if fc_errors_df[fc_errors_df['id'] == idx].test_category.item() == 'simple':\n",
    "        # check if fc model has multiple function calls which repeat\n",
    "        fc_response = fc_df[fc_df['idx'] == (idx-1)]['result'].item()\n",
    "        print(f\"Num FC responses: {len(fc_response)}\")\n",
    "        if len(fc_response) > 1:\n",
    "            same_bool = [response == fc_response[0] for response in fc_response]\n",
    "            if sum(same_bool) == len(same_bool):\n",
    "                print(f\"!!! FC model repeated the same function call {len(fc_response)} times. !!!\")\n",
    "            else:\n",
    "                print(f\"FC model had multiple different function calls. Weird.\")\n",
    "        \n",
    "\n",
    "    print(\"Prompt Model: \", prompt_df[prompt_df['idx'] == (idx-1)]['result'].item())\n",
    "    if idx in prompt_errors_df.id.values:\n",
    "        print(\"Prompt model also made an error. This is not a clear FC error.\")\n",
    "        print(\"Prompt Error: \", prompt_errors_df[prompt_errors_df['id'] == idx]['error'].item())\n",
    "    else:\n",
    "        print(\"Prompt model got it right.\")\n",
    "\n",
    "    if fc_errors_df[fc_errors_df['id'] == idx]['test_category'].item() == 'relevance':\n",
    "        with open(\"data/gorilla_openfunctions_v1_test_relevance.json\", 'r') as f:\n",
    "            data = [json.loads(line) for line in f.readlines()]\n",
    "            question_df = pd.DataFrame(data)\n",
    "    elif fc_errors_df[fc_errors_df['id'] == idx].test_category.item() == 'simple':\n",
    "        with open(\"data/gorilla_openfunctions_v1_test_simple.json\", 'r') as f:\n",
    "            data = [json.loads(line) for line in f.readlines()]\n",
    "            question_df = pd.DataFrame(data)\n",
    "    else:\n",
    "        raise ValueError(f\"Not implemented for test categories {fc_errors_df[fc_errors_df['id'] == idx].test_category.item()}.\")\n",
    "    \n",
    "    print(\"Question: \", question_df.iloc[idx-1]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 121 (WHICH IS SECRETLY) 120 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Valid syntax. Successfully decode AST when it should not.']\n",
      "FC Model:  [{'caffeine_effect': '{\"caffeine_content\":95,\"drinking_frequency\":\"daily\"}'}]\n",
      "Prompt Model:  NO tools call.\n",
      "Prompt model got it right.\n",
      "Question:  What's the neurological impact of sports on human brain?\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_relevance_errors,\n",
    "                     gpt3_5_fc_relevance_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_relevance_results,\n",
    "                     idx=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/gorilla_openfunctions_v1_test_relevance.json\", 'r') as f:\n",
    "#     data = [json.loads(line) for line in f.readlines()]\n",
    "#     question_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 113 (WHICH IS SECRETLY) 112 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Valid syntax. Successfully decode AST when it should not.']\n",
      "FC Model:  [{'geocode_address': '{\"address\":\"New York, USA\"}'}]\n",
      "Prompt Model:  [geocode_address(address='New York')]\n",
      "Prompt model also made an error. This is not a clear FC error.\n",
      "Prompt Error:  ['Valid syntax. Successfully decode AST when it should not.']\n",
      "Question:  What's the current traffic condition in New York?\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_relevance_errors,\n",
    "                     gpt3_5_fc_relevance_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_relevance_results,\n",
    "                     idx=113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 135 (WHICH IS SECRETLY) 134 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Valid syntax. Successfully decode AST when it should not.']\n",
      "FC Model:  [{'calculate_battle_outcome': '{\"battle_name\": \"World Cup 2022 Final\", \"strategy_type\": \"football\"}'}, {'calculate_battle_outcome': '{\"battle_name\": \"World Cup 2022 Final\", \"strategy_type\": \"football\"}'}]\n",
      "Prompt Model:  [This question does not relate to the available function. No function applies.]\n",
      "Prompt model got it right.\n",
      "Question:  Who won the World Cup 2022?\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_relevance_errors,\n",
    "                     gpt3_5_fc_relevance_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_relevance_results,\n",
    "                     idx=135\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'calculate_battle_outcome',\n",
       " 'description': 'Predicts the outcome of a historical battle based on the strategies, army size and other influencing factors.',\n",
       " 'parameters': {'type': 'dict',\n",
       "  'properties': {'battle_name': {'type': 'string',\n",
       "    'description': 'The name of the historical battle.'},\n",
       "   'strategy_type': {'type': 'string',\n",
       "    'description': 'The strategy employed in the battle.'},\n",
       "   'weather_condition': {'type': 'string',\n",
       "    'description': 'Weather condition during the battle.',\n",
       "    'default': 'snowing'}},\n",
       "  'required': ['battle_name', 'strategy_type']}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/gorilla_openfunctions_v1_test_relevance.json\", 'r') as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "    question_df = pd.DataFrame(data)\n",
    "\n",
    "question_df.iloc[134].function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^honestly not bad. Pretty innovative way to use an irrelevant function to make it look relevant. Still wrong, but I'm impressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaway: Prompt model understands when the passed functions are irrelevant and says no. But the FC model almost always returns a function call even though it makes no sense and gets Rekt. I suspect this is an issue with the way BFCL is calling the FC model. But will verify after implementing for DBRX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compare for simple\n",
    "gpt3_5_fc_simple_errors = error_result_df[(error_result_df['filename'] == 'simple_score.json') & (error_result_df['model_name'] == 'gpt-3.5-turbo-0125-FC')]\n",
    "gpt3_5_fc_simple_results = full_result_df[(full_result_df['filename'] == 'gorilla_openfunctions_v1_test_simple_result.json') & (full_result_df['model_name'] == 'gpt-3.5-turbo-0125-FC')]\n",
    "gpt3_5_prompt_simple_errors = error_result_df[(error_result_df['filename'] == 'simple_score.json') & (error_result_df['model_name'] == 'gpt-3.5-turbo-0125')]\n",
    "gpt3_5_prompt_simple_results = full_result_df[(full_result_df['filename'] == 'gorilla_openfunctions_v1_test_simple_result.json') & (full_result_df['model_name'] == 'gpt-3.5-turbo-0125')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 335 (WHICH IS SECRETLY) 334 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'blackjack_check_winner': '{\"player_cards\": [\"A\", \"10\"], \"dealer_cards\": [\"10\", \"9\"], \"ace_value\": 1}'}, {'blackjack_check_winner': '{\"player_cards\": [\"A\", \"10\"], \"dealer_cards\": [\"10\", \"9\"], \"ace_value\": 11}'}]\n",
      "Num FC responses: 2\n",
      "FC model had multiple different function calls. Weird.\n",
      "Prompt Model:  [blackjack.check_winner(player_cards=['A', '10'], dealer_cards=['10', '9'], ace_value=1)]\n",
      "Prompt model got it right.\n",
      "Question:  Check who is the winner in a game of blackjack given player having A and 10, dealer having 10 and 9. The Ace is considered 1.\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 37 (WHICH IS SECRETLY) 36 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC [\"Invalid value for parameter 'unit': 'mi'. Expected one of ['km', '']. Case insensitive.\"]\n",
      "FC Model:  [{'get_shortest_driving_distance': '{\"origin\":\"New York City\",\"destination\":\"Washington D.C.\",\"unit\":\"mi\"}'}]\n",
      "Num FC responses: 1\n",
      "Prompt Model:  [get_shortest_driving_distance(origin='New York City', destination='Washington D.C.')]\n",
      "Prompt model got it right.\n",
      "Question:  Find the shortest driving distance between New York City and Washington D.C.\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 382 (WHICH IS SECRETLY) 381 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'hilton_hotel_check_availability': '{\"location\": \"Paris\", \"check_in_date\": \"2023-04-04\", \"check_out_date\": \"2023-04-08\", \"no_of_adults\": 2}'}, {'hilton_hotel_check_availability': '{\"location\": \"Paris\", \"check_in_date\": \"2023-04-04\", \"check_out_date\": \"2023-04-08\", \"no_of_adults\": 2, \"hotel_chain\": \"Hilton Garden Inn\"}'}]\n",
      "Num FC responses: 2\n",
      "FC model had multiple different function calls. Weird.\n",
      "Prompt Model:  [{'name': 'hilton_hotel.check_availability', 'parameters': {'location': 'Paris', 'check_in_date': '2023-04-04', 'check_out_date': '2023-04-08', 'no_of_adults': 2}}]\n",
      "Prompt model got it right.\n",
      "Question:  Check if any Hilton Hotel is available for two adults in Paris from April 4th to April 8th?\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 381 (WHICH IS SECRETLY) 380 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'hotel_booking': '{\"location\": \"Manhattan, New York\", \"room_type\": \"single\", \"duration\": 3, \"start_date\": \"2023-03-10\", \"preferences\": [\"pet_friendly\"]}'}, {'hotel_booking': '{\"location\": \"Manhattan, New York\", \"room_type\": \"single\", \"duration\": 3, \"start_date\": \"2023-03-10\", \"preferences\": [\"pet_friendly\"]}'}]\n",
      "Num FC responses: 2\n",
      "!!! FC model repeated the same function call 2 times. !!!\n",
      "Prompt Model:  [hotel_booking(location='Manhattan, New York', room_type='single', duration=3, start_date='March 10th, 2023', preferences=['pet_friendly'])]\n",
      "Prompt model got it right.\n",
      "Question:  Book a single room at a pet friendly hotel near Manhattan, New York for 3 nights starting from March 10th, 2023.\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=381)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 383 (WHICH IS SECRETLY) 382 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}, {'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}]\n",
      "Num FC responses: 2\n",
      "!!! FC model repeated the same function call 2 times. !!!\n",
      "Prompt Model:  [book_hotel(hotel_name='Hilton Hotel', location='Chicago', room_type='single', start_date='10th December 2022', nights=2)]\n",
      "Prompt model got it right.\n",
      "Question:  Book a single room for two nights at the Hilton Hotel in Chicago, starting from 10th December 2022.\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=383)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_calls = [{'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}, {'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}]\n",
    "fun_calls[0] == fun_calls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 286 (WHICH IS SECRETLY) 285 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'find_concert': '{\"location\": \"Chicago, IL\", \"price\": 100, \"genre\": \"Rock\"}'}, {'find_concert': '{\"location\": \"Chicago, IL\", \"price\": 100, \"genre\": \"Pop\"}'}, {'find_concert': '{\"location\": \"Chicago, IL\", \"price\": 100, \"genre\": \"Country\"}'}]\n",
      "Num FC responses: 3\n",
      "FC model had multiple different function calls. Weird.\n",
      "Prompt Model:  [find_concert(location='Chicago, IL', price=100, genre='Rock')]\n",
      "Prompt model got it right.\n",
      "Question:  Find me a Rock concert in Chicago with ticket availability under $100.\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 128 (WHICH IS SECRETLY) 127 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'calculate_NPV': '{\"cash_flows\": [200, 300, 400, 500], \"discount_rate\": 0.1, \"initial_investment\": 2000}'}, {'calculate_NPV': '{\"cash_flows\": [-2000, 200, 300, 400, 500], \"discount_rate\": 0.1}'}]\n",
      "Num FC responses: 2\n",
      "FC model had multiple different function calls. Weird.\n",
      "Prompt Model:  [calculate_NPV(cash_flows=[200,300,400,500], discount_rate=0.1, initial_investment=2000)]\n",
      "Prompt model got it right.\n",
      "Question:  Find the Net Present Value (NPV) of an investment, given cash_flows=[200,300,400,500], a discount rate of 10%, and an initial investment of $2000.\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                              179\n",
       "unique                              25\n",
       "top       [Wrong number of functions.]\n",
       "freq                               155\n",
       "Name: error, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_simple_errors.error.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The FC model repeats function calls 42/179 times.\n"
     ]
    }
   ],
   "source": [
    "def check_if_funcall_repeats(fc_errors_df, fc_df, prompt_errors_df, prompt_df, idx=None):\n",
    "    if idx is None:\n",
    "        fc_only_errors = set(fc_errors_df.id.values) - set(prompt_errors_df.id.values)\n",
    "        idx = np.random.choice(list(fc_only_errors))\n",
    "    # print(f'Looking at idx: {idx} (WHICH IS SECRETLY) {idx - 1} in the results.json')\n",
    "    # print(f\"Error: {fc_errors_df.model_name.unique()[0]}\", fc_errors_df[fc_errors_df['id'] == idx]['error'].item())\n",
    "    # print(\"FC Model: \", fc_df[fc_df['idx'] == (idx-1)]['result'].item())\n",
    "\n",
    "    if fc_errors_df[fc_errors_df['id'] == idx].test_category.item() == 'simple':\n",
    "        # check if fc model has multiple function calls which repeat\n",
    "        fc_response = fc_df[fc_df['idx'] == (idx-1)]['result'].item()\n",
    "        # print(f\"Num FC responses: {len(fc_response)}\")\n",
    "        if len(fc_response) > 1:\n",
    "            same_bool = [response == fc_response[0] for response in fc_response]\n",
    "            if sum(same_bool) == len(same_bool):\n",
    "                # print(f\"!!! FC model repeated the same function call {len(fc_response)} times. !!!\")\n",
    "                return True\n",
    "            else:\n",
    "                # print(f\"FC model had multiple different function calls. Weird.\")\n",
    "                return False\n",
    "        \n",
    "num_fc_repeats = 0\n",
    "for idx in gpt3_5_fc_simple_errors.id.values:\n",
    "    if check_if_funcall_repeats(gpt3_5_fc_simple_errors,\n",
    "                                gpt3_5_fc_simple_results,\n",
    "                                gpt3_5_prompt_simple_errors,\n",
    "                                gpt3_5_prompt_simple_results,\n",
    "                                idx=idx):\n",
    "        num_fc_repeats += 1\n",
    "print(f\"The FC model repeats function calls {num_fc_repeats}/{gpt3_5_fc_simple_errors.shape[0]} times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so it looks like 155/179 errors are due to the FC model trying multiple function calls when it should have just invoked the one function, once. Sometimes (42 times) it repeats the same function call, but quite often (137 times) it just makes multiple function calls. This is not just a parsing issue, it could be a prompting issue/incorrect way to use the openAI api. Not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexus-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
